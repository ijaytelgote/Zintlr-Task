{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef22c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2371c9f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"full_name\": \"Pankaj Joshi\",\n",
      "    \"first_name\": \"Pankaj\",\n",
      "    \"last_name\": \"Joshi\",\n",
      "    \"industry\": \"IT Services & Consulting\",\n",
      "    \"annual_salary\": \"4y 1m\\u00e2\\u201a\\u00b9 9.50 Lacs (expects: \\u00e2\\u201a\\u00b9 10.0 Lacs)Noida\",\n",
      "    \"education\": [\n",
      "        {\n",
      "            \"degree\": \"BCA\",\n",
      "            \"major\": \"Computers\",\n",
      "            \"year\": \"2020 UG\",\n",
      "            \"institute\": \"Ch Charan Singh University (CCSU), Meerut\"\n",
      "        }\n",
      "    ],\n",
      "    \"work_experience\": [\n",
      "        {\n",
      "            \"company_logo_url\": \"https://img.naukimg.com/logo_images/groups/v1/4598093.gif\",\n",
      "            \"company_name\": \"Girikon Solutions Pvt Ltd logo\",\n",
      "            \"designation\": \"Fullstack Developer at Girikon Solutions Pvt Ltd\",\n",
      "            \"dates\": \"Apr '23 till date (\\n                \\n            \\n            10m\\n            )\",\n",
      "            \"description\": \"\\u00e2\\u20ac\\u00a2 Developing front end website architecture.\\n\\u00e2\\u20ac\\u00a2 Designing user interactions on web pages.\\n\\u00e2\\u20ac\\u00a2 Developing back-end website applications.\\n\\u00e2\\u20ac\\u00a2 Creating servers and databases for functionality.\\n\\u00e2\\u20ac\\u00a2 Ensuring cross-platform optimization for mobile phones.\\n\\u00e2\\u20ac\\u00a2 Ensuring responsiveness of applications.\\n\\u00e2\\u20ac\\u00a2 Working alongside graphic designers for web design features.\\n\\u00e2\\u20ac\\u00a2 Seeing through a project from conception to finished product.\\n\\u00e2\\u20ac\\u00a2 Designing and developing APIs.\\n\\u00e2\\u20ac\\u00a2 Meeting both technical and consumer needs.\\n\\u00e2\\u20ac\\u00a2 Staying abreast of developments in web applications and programming languages.\"\n",
      "        },\n",
      "        {\n",
      "            \"company_logo_url\": \"https://img.naukimg.com/logo_images/groups/v1/8317097.gif\",\n",
      "            \"company_name\": \"Leadingdots Solutions Pvt Ltd logo\",\n",
      "            \"designation\": \"Web Developer at Leadingdots Solutions Pvt Ltd\",\n",
      "            \"dates\": \"May '22 till Mar '23 (\\n                \\n            \\n            10m\\n            )\",\n",
      "            \"description\": \"Designed and developed web applications across multiple APIs, third-party integrations and databases. Passionate and hardworking with penchant for developing customized interfaces that factor in unique demands for accessibility, reachability and security.\"\n",
      "        },\n",
      "        {\n",
      "            \"company_logo_url\": \"https://img.naukimg.com/logo_images/groups/v1/4483868.gif\",\n",
      "            \"company_name\": \"Apponward Technologies logo\",\n",
      "            \"designation\": \"Senior Php Developer at Apponward Technologies\",\n",
      "            \"dates\": \"Sep '19 till May '22 (\\n                2y\\n             \\n            8m\\n            )\",\n",
      "            \"description\": \"I have good in hand experience  in php language and laravel\\nI am working in backend and i use php,python,django,laravel \\n\\nSkills :\\nPHP, JQUERY, MYSQL, AJAX, LARAVEL, PAYMENT GATEWAYS, HTML, CSS, SOAP AND REST API'S, ANGULAR, JAVASCRIPT, CI,PYTHON,DJANGO,DJANGO REST FRAMEWORK\\n\\nmy recent completed projects :\\nhttps://www.urwagon.com/fly/public/ -> project to ship packages internationally (in laravel)\\nhttps://flowmixx.com/             -> music website (backend in laravel and frontend in angular\\nhttps://www.oxygentimes.com/     -> projects for comparing oxygen Concentrator\"\n",
      "        }\n",
      "    ],\n",
      "    \"skills\": [\n",
      "        \"Laravel\",\n",
      "        \"Node.js\",\n",
      "        \"PHP\",\n",
      "        \"sqlserver|plsql|laravel|digital marketing|php|codeigniter|javascript|web development|css|mysql|jquery|+19 more\",\n",
      "        \"React.js|sql|html|php|codeigniter|jquery|javascript|mysql|laravel|node.js|mongodb|Bootstrap\",\n",
      "        \"Mern Stack|React.Js|Node.Js|Node Api|Node Express|Nextjs|Pwa|MongoDB|MySQL|+3 more\",\n",
      "        \"Full Stack Developer|MEAN Stack Developer|javascript|java|python|html|aws|node.js|jenkins|docker|+21 more\",\n",
      "        \"OOP|MySQL|Javascript|Laravel PHP Framework|Rest Api Development|JQuery|React.Js|Docker|+9 more\",\n",
      "        \"SEO|Pyspark|Numpy|Pandas|HTML|CSS|MySQL|PHP|Bootstrap|jQuery|Laravel|API|Ajax|Python\",\n",
      "        \"HTML|React.js|Laravel PHP|CSS|Javascript|Bootstrap|MySQL|MVC|PHP|jQuery|Ajax|PHP Developer|+4 more\"\n",
      "    ],\n",
      "    \"work_summary\": \"I am a full stack developer working with LAMP Stack (Laravel Framework) and Node.js, Express.js, React.js (MERN Stack).\",\n",
      "    \"it_skills\": [\n",
      "        {\n",
      "            \"skill\": \"Laravel\",\n",
      "            \"version\": \"9\",\n",
      "            \"last_used\": \"2023\",\n",
      "            \"experience\": \"4y\"\n",
      "        },\n",
      "        {\n",
      "            \"skill\": \"Node.js\",\n",
      "            \"version\": \"18.14\",\n",
      "            \"last_used\": \"2023\",\n",
      "            \"experience\": \"2y\"\n",
      "        },\n",
      "        {\n",
      "            \"skill\": \"PHP\",\n",
      "            \"version\": \"8\",\n",
      "            \"last_used\": \"2023\",\n",
      "            \"experience\": \"4y\"\n",
      "        }\n",
      "    ],\n",
      "    \"other_details\": {\n",
      "        \"languages_known\": {\n",
      "            \"hindi\\n         -\\n         Expert ( Read,Write,Speak )\": \"( Read,Write,Speak )\",\n",
      "            \"english\\n         -\\n         Expert ( Read,Write,Speak )\": \"( Read,Write,Speak )\"\n",
      "        },\n",
      "        \"personal_details\": {},\n",
      "        \"desired_job_details\": {\n",
      "            \"Permanent / Temporary\": \"Full Time, Part Time\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "class ProfileScraper:\n",
    "    def __init__(self, html_content):\n",
    "        \"\"\"\n",
    "        Initialized the ProfileScraper object with the provided HTML content.\n",
    "        \"\"\"\n",
    "        self.soup = BeautifulSoup(html_content, 'html.parser')  # Created a BeautifulSoup object\n",
    "        self.profile_data = {}  # Initialized an empty dictionary to store profile data\n",
    "\n",
    "    def extract_full_name(self):\n",
    "        \"\"\"\n",
    "        Extracted full name from the HTML content.\n",
    "        \"\"\"\n",
    "        full_name_tag = self.soup.find('div', class_='name')  # Found the tag containing the full name\n",
    "        if full_name_tag:\n",
    "            full_name = full_name_tag.text.strip()  # Got the text content and removed leading/trailing whitespace\n",
    "            self.profile_data['full_name'] = full_name  # Added full name to profile data dictionary\n",
    "            self.profile_data['first_name'], self.profile_data['last_name'] = full_name.split(maxsplit=1)  # Split full name into first and last names\n",
    "\n",
    "    def extract_industry(self):\n",
    "        \"\"\"\n",
    "        Extracted industry information from the HTML content.\n",
    "        \"\"\"\n",
    "        industry_tag = self.soup.find('div', class_='OesXg')  # Found the tag containing industry information\n",
    "        if industry_tag:\n",
    "            self.profile_data['industry'] = industry_tag.text.strip()  # Added industry information to profile data dictionary\n",
    "\n",
    "    def extract_annual_salary(self):\n",
    "        \"\"\"\n",
    "        Extracted annual salary information from the HTML content.\n",
    "        \"\"\"\n",
    "        salary_element = self.soup.find('div', class_='vOrcj')  # Found the element containing annual salary\n",
    "        if salary_element:\n",
    "            self.profile_data['annual_salary'] = salary_element.text.strip()  # Added annual salary to profile data dictionary\n",
    "\n",
    "    def extract_education(self):\n",
    "        \"\"\"\n",
    "        Extracted education information from the HTML content.\n",
    "        \"\"\"\n",
    "        education_elements = self.soup.find_all('div', class_='edu-label')  # Found all education elements\n",
    "        education_info = []\n",
    "\n",
    "        for edu_element in education_elements:\n",
    "            education_dict = {}\n",
    "            degree_year = edu_element.find('div', class_='desig').text.strip()  # Extracted degree and year\n",
    "            education_dict['degree'] = degree_year.split(',')[0].strip()\n",
    "            education_dict['major'] = degree_year.split(',')[1].strip()\n",
    "            education_dict['year'] = degree_year.split(',')[2].strip()\n",
    "            institute = edu_element.find('span', class_='hlite-inherit').text.strip()  # Extracted institute name\n",
    "            education_dict['institute'] = institute\n",
    "            education_info.append(education_dict)\n",
    "\n",
    "        self.profile_data['education'] = education_info  # Added education information to profile data dictionary\n",
    "\n",
    "    def extract_work_experience(self):\n",
    "        \"\"\"\n",
    "        Extracted work experience information from the HTML content.\n",
    "        \"\"\"\n",
    "        work_experience_section = self.soup.find('div', class_='work-exp')\n",
    "        work_experience = []\n",
    "\n",
    "        if work_experience_section:\n",
    "            work_exp_cards = work_experience_section.find_all('div', class_='work-exp-card')\n",
    "            for card in work_exp_cards:\n",
    "                exp_head = card.find('div', class_='exp-head')\n",
    "                if exp_head:\n",
    "                    exp_icon = exp_head.find('div', class_='exp-icon')\n",
    "                    if exp_icon:\n",
    "                        exp_img = exp_icon.find('img')\n",
    "                        if exp_img:\n",
    "                            company_logo_url = exp_img.get('data-src', '')\n",
    "                            company_name = exp_img.get('alt', '')\n",
    "                    exp_label = exp_head.find('div', class_='exp-label')\n",
    "                    if exp_label:\n",
    "                        desig = exp_label.find('div', class_='desig').text.strip()\n",
    "                        dates = exp_label.find('div', class_='dates').text.strip()\n",
    "                    desc = card.find('div', class_='desc').text.strip()\n",
    "                    work_experience.append({\n",
    "                        'company_logo_url': company_logo_url,\n",
    "                        'company_name': company_name,\n",
    "                        'designation': desig,\n",
    "                        'dates': dates,\n",
    "                        'description': desc\n",
    "                    })\n",
    "\n",
    "        self.profile_data['work_experience'] = work_experience\n",
    "\n",
    "    def extract_skills(self):\n",
    "        \"\"\"\n",
    "        Extracted skills information from the HTML content.\n",
    "        \"\"\"\n",
    "        skills_elements = self.soup.find_all('div', class_='skills')\n",
    "        if skills_elements:\n",
    "            skills = [item.text.strip() for item in skills_elements]\n",
    "            self.profile_data['skills'] = skills\n",
    "\n",
    "    def extract_work_summary(self):\n",
    "        \"\"\"\n",
    "        Extracted work summary information from the HTML content.\n",
    "        \"\"\"\n",
    "        work_summary_section = self.soup.find('div', class_='_2NDnc')\n",
    "        work_summary = ''\n",
    "\n",
    "        if work_summary_section:\n",
    "            work_summary = work_summary_section.find('div', class_='Ju-0N').text.strip()\n",
    "\n",
    "        self.profile_data['work_summary'] = work_summary\n",
    "\n",
    "    def extract_it_skills(self):\n",
    "        \"\"\"\n",
    "        Extracted IT skills information from the HTML content.\n",
    "        \"\"\"\n",
    "        it_skills_section = self.soup.find('div', class_='cv-prev-it-skills')\n",
    "        it_skills_info = []\n",
    "\n",
    "        if it_skills_section:\n",
    "            it_skills_rows = it_skills_section.find_all('div', class_='table-tuple')\n",
    "\n",
    "            for row in it_skills_rows:\n",
    "                skill_elem = row.find('div', class_='data-cell skills')\n",
    "                version_elem = row.find('div', class_='data-cell version')\n",
    "                last_used_elem = row.find('div', class_='data-cell lastUsed')\n",
    "                exp_elem = row.find('div', class_='data-cell exp')\n",
    "\n",
    "                if skill_elem and version_elem and last_used_elem and exp_elem:\n",
    "                    skill = skill_elem.text.strip()\n",
    "                    version = version_elem.text.strip()\n",
    "                    last_used = last_used_elem.text.strip()\n",
    "                    experience = exp_elem.text.strip()\n",
    "\n",
    "                    it_skill_data = {\n",
    "                        'skill': skill,\n",
    "                        'version': version,\n",
    "                        'last_used': last_used,\n",
    "                        'experience': experience\n",
    "                    }\n",
    "\n",
    "                    it_skills_info.append(it_skill_data)\n",
    "\n",
    "        self.profile_data['it_skills'] = it_skills_info\n",
    "\n",
    "    def extract_other_details(self):\n",
    "        \"\"\"\n",
    "        Extracted other details such as languages known, personal details, and desired job details from the HTML content.\n",
    "        \"\"\"\n",
    "        other_details_section = self.soup.find('div', class_='YQo1I')\n",
    "        other_details = {}\n",
    "\n",
    "        if other_details_section:\n",
    "            languages_known = {}\n",
    "            languages_section = other_details_section.find('div', class_='_88wuB')\n",
    "            if languages_section:\n",
    "                languages_items = languages_section.find_all('div', class_='_9FKxR')\n",
    "                for item in languages_items:\n",
    "                    language_name = item.text.strip().split(' - ')[0]\n",
    "                    proficiency = item.find('span', class_='_5F2Uo').text.strip()\n",
    "                    languages_known[language_name] = proficiency\n",
    "            other_details['languages_known'] = languages_known\n",
    "\n",
    "            personal_details = {}\n",
    "            personal_details_section = other_details_section.find('div', class_='nqhGZ')\n",
    "            if personal_details_section:\n",
    "                personal_info_rows = personal_details_section.find_all('div', class_='tr')\n",
    "                for row in personal_info_rows:\n",
    "                    details = row.find_all('div', class_='table-cell')\n",
    "                    if len(details) == 2:\n",
    "                        key = details[0].text.strip()\n",
    "                        value = details[1].text.strip()\n",
    "                        personal_details[key] = value\n",
    "            other_details['personal_details'] = personal_details\n",
    "\n",
    "            desired_job_details = {}\n",
    "            desired_job_section = other_details_section.find('div', class_='hmFnB')\n",
    "            if desired_job_section:\n",
    "                job_info_rows = desired_job_section.find_all('div', class_='tr')\n",
    "                for row in job_info_rows:\n",
    "                    details = row.find_all('div', class_='table-cell')\n",
    "                    if len(details) == 2:\n",
    "                        key = details[0].text.strip()\n",
    "                        value = details[1].text.strip()\n",
    "                        desired_job_details[key] = value\n",
    "            other_details['desired_job_details'] = desired_job_details\n",
    "\n",
    "        self.profile_data['other_details'] = other_details\n",
    "\n",
    "    def scrape_profile(self):\n",
    "        \"\"\"\n",
    "        Scraped profile information using all extraction methods.\n",
    "        \"\"\"\n",
    "        self.extract_full_name()\n",
    "        self.extract_industry()\n",
    "        self.extract_annual_salary()\n",
    "        self.extract_education()\n",
    "        self.extract_work_experience()\n",
    "        self.extract_skills()\n",
    "        self.extract_work_summary()\n",
    "        self.extract_it_skills()\n",
    "        self.extract_other_details()\n",
    "\n",
    "        return self.profile_data\n",
    "\n",
    "def main():\n",
    "    with open(Path_of_file, 'r') as file:\n",
    "        raw_html = file.read()  # Read HTML content from file\n",
    "\n",
    "    # Initialized ProfileScraper object with HTML content\n",
    "    scraper = ProfileScraper(raw_html)\n",
    "\n",
    "    # Scraped profile information\n",
    "    profile_data = scraper.scrape_profile()\n",
    "\n",
    "    # Converted dictionary to JSON format\n",
    "    json_data = json.dumps(profile_data, indent=4)  # Converted dictionary to JSON string with indentation\n",
    "    print(json_data)  # Printed JSON data\n",
    "\n",
    "# Executed main function if the script was run directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01e86f8",
   "metadata": {},
   "source": [
    "\n",
    "---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---    \n",
    "List of approaches, techniques, and packages used in the code:\n",
    "\n",
    "Object-Oriented Programming (OOP) Technique\n",
    "   - The code uses the object-oriented programming (OOP) paradigm to encapsulate related functionality within classes (`ProfileScraper`).\n",
    "   - Methods are defined within the class to perform specific tasks related to profile scraping.\n",
    "\n",
    "HTML Parsing Techniqu\n",
    "   - The code uses BeautifulSoup, a Python library, for parsing HTML documents (`BeautifulSoup`).\n",
    "   - BeautifulSoup is used to navigate and search through the HTML content to locate specific elements containing the desired information.\n",
    "\n",
    "Data Extraction Technique\n",
    "   - The code utilizes various data extraction techniques to extract specific pieces of information from the HTML content.\n",
    "   - These techniques include finding elements by class name (`find` and `find_all` methods) and extracting text content (`text` attribute).\n",
    "\n",
    "Data Storage Technique\n",
    "   - The extracted profile data is stored in a dictionary (`profile_data`) within the `ProfileScraper` class.\n",
    "   - The dictionary structure allows for easy organization and retrieval of profile information.\n",
    "\n",
    "JSON Serialization Technique\n",
    "   - The code uses the `json` package to serialize the extracted profile data into JSON format.\n",
    "   - JSON serialization allows for easy storage, transmission, and interchange of data in a structured format.\n",
    "\n",
    "HTTP Request Technique\n",
    "   - Although not explicitly shown in the provided code, web scraping often involves making HTTP requests to fetch HTML content from web pages.\n",
    "   - The `requests` library is commonly used for making HTTP requests in Python.\n",
    "\n",
    "File I/O Technique\n",
    "   - The code reads HTML content from a file using file input/output operations (`open` function).\n",
    "   - This allows for scraping data from locally stored HTML files.\n",
    "\n",
    "Printing Technique\n",
    "   - The extracted profile data in JSON format is printed to the console using the `print` function.\n",
    "\n",
    "Package Used\n",
    "    - `requests`: Used for making HTTP requests to fetch HTML content from web pages.\n",
    "    - `BeautifulSoup`: Used for parsing HTML documents and navigating the HTML tree structure to extract specific elements.\n",
    "    - `json`: Used for serializing Python objects (in this case, the profile data dictionary) into JSON format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb6fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a40601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed175dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905f07f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da6418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c2b347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
